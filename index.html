<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head><meta name="generator" content="Hexo 3.9.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta property="og:type" content="website">
<meta property="og:title" content="Qi-Liang&#39;blog">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="Qi-Liang&#39;blog">
<meta property="og:locale" content="zh-Hans">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Qi-Liang&#39;blog">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/">





  <title>Qi-Liang'blog</title>
  








</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Qi-Liang'blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">stay young,stay simple</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            归档
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/10/Command/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/10/Command/" itemprop="url">Linux常用命令</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-10T18:39:48+08:00">
                2019-11-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="查看系统版本"><a href="#查看系统版本" class="headerlink" title="查看系统版本"></a>查看系统版本</h1><p>查看ubuntu的内核版本和发行版本号，可以采用如下命令</p>
<ul>
<li><strong>内核版本</strong></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">liangqi@ubuntu:~$ uname -r</span><br><span class="line">4.15.0-66-generic</span><br></pre></td></tr></table></figure>

<ul>
<li><strong>内核信息</strong></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">liangqi@ubuntu:~$ uname -a</span><br><span class="line">Linux ubuntu 4.15.0-66-generic <span class="comment">#75~16.04.1-Ubuntu SMP Tue Oct 1 14:01:08 UTC 2019 x86_64 x86_64 x86_64 GNU/Linux</span></span><br></pre></td></tr></table></figure>

<ul>
<li><strong>发行版本</strong></li>
</ul>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">liangqi@ubuntu:~$ sudo lsb_release -a</span><br><span class="line">No LSB modules are available.</span><br><span class="line">Distributor ID:	Ubuntu</span><br><span class="line">Description:	Ubuntu 16.04.6 LTS</span><br><span class="line">Release:	16.04</span><br><span class="line">Codename:	xenial</span><br></pre></td></tr></table></figure>

<p>或者</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">liangqi@ubuntu:~$ cat /etc/issue</span><br><span class="line">Ubuntu 16.04.6 LTS \n \l</span><br></pre></td></tr></table></figure>

<blockquote>
<p>本文的所有命令均是对应上面的Ubuntu版本</p>
</blockquote>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/10/basic/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/10/basic/" itemprop="url">basic</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-10T12:51:52+08:00">
                2019-11-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/C/" itemprop="url" rel="index">
                    <span itemprop="name">C++</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/C/CMake/" itemprop="url" rel="index">
                    <span itemprop="name">CMake</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/09/Unsupervised Learning Deep Generative Model/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/09/Unsupervised Learning Deep Generative Model/" itemprop="url">Unsupervised Learning —— Deep Generative Model</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-09T10:04:51+08:00">
                2019-11-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>有关generative model，链接1是openAI写的一篇科普文章。</p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://openai.com/blog/generative-models/" target="_blank" rel="noopener">Generative Models</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/05/Unsupervised Learning Auto-encoder/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/05/Unsupervised Learning Auto-encoder/" itemprop="url">Unsupervised Learning —— Auto-encoder</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-05T17:29:38+08:00">
                2019-11-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><p>什么是Auto-encoder呢？Auto-encoder的想法是，我们先去找一个encoder，这个encoder可以input一个东西，例如影响辨识，input一张784维的vector表示的digit。这个encoder它可能就是一个neural network，它的output就是一个code，这个code通常远比784维还要小，所以会有类似压缩的效果。这个code代表input这张image的某种compact，某种精简有效的representation。</p>
<p>现在的问题是，我们做的是unsupervised learning，可以找到一大堆的image当作NN encoder的input，但是我们没有任何的output，即不知道一个image应该变成什么样的code。要learn一个network需要有input和output，所有只有input没办法去learn。</p>
<p>我们先做另外一件事情，learn一个decoder，这个decoder做的事情是：input一个vector，它就通过这个decoder output一张image。但是我们也没有办法train NN的decoder，因为只有output。这两个network,encoder和decoder，每个我们都无法单独去train。但我们可以把它接起来，然后一起train。也就是说，我们接一个neural network，input一个image，中间变成code，再把code通过decoder变成原来的image，就可以把encoder和decode同时学出来。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/1.png" alt="1"></p>
<h1 id="Starting-from-PCA"><a href="#Starting-from-PCA" class="headerlink" title="Starting from PCA"></a>Starting from PCA</h1><p>我们之前在PCA里面其实看过非常类似的概念。PCA实际上做的事情是，input一张image $x$(通常我们会把$x$减掉它的平均$\bar{x}$当作input，但这里我们把它省略掉，这样并不会它奇怪，因为通常在做NN的时候，拿到data首先就会做normalize，把它变成mean是0，variance是1，所以就不用再减掉$\bar{x}$了)，$x$乘上一个weight,通过NN的一个layer，得到component的weight $c$，$c$再乘上matrix $W^T$得到$\hat{x}$，$\hat{x}$是根据这些component的weight和component做reconstruction的结果。在PCA里面，我们要做的事情就是minimize input跟reconstruction的结果。如果它它当成neural network来看的话，input $x$就是input layer，output $\hat{x}$就是output layer，中间component weight就是hidden layer，在PCA里面它是linear的。中间的hidden layer我们通常称为<strong>Bottleneck layer</strong>,这么叫是因为我们现在要做dimension reduction,所以component的数目通常会比input的dimension还要小得多，所以如果把它当作一个layer来看的话，它是一个特别窄的layer。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/2.png" alt="2"></p>
<h2 id="Deep-Auto-encoder"><a href="#Deep-Auto-encoder" class="headerlink" title="Deep Auto-encoder"></a>Deep Auto-encoder</h2><p>PCA是这么做的，其实也可以用gradient decent来做PCA。但PCA只有一个hidden layer，我们想能不能把它变更多的hidden layer？当然可以，就兜一个很深的neural network，它有很多很多的层，同样我们希望input $x$和output $\hat{x}$越接近越好。测试的方法完全没有什么特别，就是backpropagation。注意中间会有个特别窄的layer，这个特别窄的layer它有特别少的neuron，这些layer的output就代表了一组code。从input到Bottleneck layer的部分就是encoder，从Bottleneck layer的output到最后的$\hat{x}$就是decoder。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/3.png" alt="3"></p>
<p>其实这个deep的auto encoder最早是Hinton提出(链接1),那个时候deep auto-encoder没有那么好train，有可能train之后结果就坏掉了，那个时候需要用RBM做layer-wise的initialization，然后才可能把deep auto-encoder train得比较好一点。如果是按照上面在PCA里面看到的，两边的layer的weight要互为transpose，在train的时候，我们可以做到这件事，只要把两边的weight tie起来，让他们在做training的时候永远保持他们的值是一样的。这样做的好处是现在auto-encoder的参数就少一半，比较不会有overfitting的情形。But symmetric is not necessary，没有什么理由两边的weight一定要互为transpose，所以现在常见的做法就是直接兜个neural network，然后用back propagation直接train下去。</p>
<p>对手写数字辨识做PCA，把它从784维降到30维，然后再从30维reconstruct回784维。可以看到最后得到的image是比较模糊的。但如果是用deep Auto-encoder的话，把784维先扩展成1000维，再降到500维、250维、30维，最后再重新变为784维。我们发现如果用deep auto-encoder的话，它的结果看起来就非常的好。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/4.png" alt="4"></p>
<p>如果我们不是把它降到30维，而是降到2维再去visualize的话，会发现，如果是做PCA，在二维的平面上，所有的digit是被混在一起。如下图，不同颜色代表了不同的数字。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/5.png" alt="5"></p>
<p>但如果是用deep auto-encoder的话，就会发现这些数字是分开的，如下图：</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/6.png" alt="6"></p>
<h1 id="Auto-encoder-——-Text-Retrieval"><a href="#Auto-encoder-——-Text-Retrieval" class="headerlink" title="Auto-encoder —— Text Retrieval"></a>Auto-encoder —— Text Retrieval</h1><p>Auto-encoder也可以用在文字处理上，比如我们会想要把一篇文章压成一个vector(code)，假设我们现在要做文字搜寻，在文字搜寻里有一种方法叫做<strong>vector space model</strong>,它就是把每篇文章都表示成空间中的一个vector，下图中每一个蓝点就是一篇文章。接下来，假设使用者输入一个查询的词汇，我们把查询的词汇也变成空间中的一个点。接下来就是计算输入的查询词汇跟每篇document之间的inner product或cosine similarity等等。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/7.png" alt="7"></p>
<p>这个模型要work,取决于现在把一个document变成一个vector表示的好不好。把document表示是vector最trivial的方法叫做bag-of-word，它的vector的size就是lexicon的size，下图是”This is an apple”这个句子的bag-of-word。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/8.png" alt="8"></p>
<p>有时候我们想要做到更好，会把它乘上inverse document frequency，每一维不只会用词汇在document出现的次数，还会再乘上一个weight，代表那个词汇的重要性。这个重要性可以用不同的方法去衡量，比如<strong>inverse document frequency</strong>。但是用这个模型很weak，它没有办法考虑任何semantic相关的东西，比如它不会知道北京大学指的就是北大，不会知道apple和orange都是水果等等，对它来说每一个词汇都是independent，词汇之间完全没有任何相关性。</p>
<p>我们可以用auto-encoder让语义这件事情被考虑进来。举例来说，我们learn一个auto-encoder，它的input就是一个document或者query(一段文字)，把一个vector变成一个vector，把这个vector通过一个encoder，把它压成二维，结果如下图。右边每个点代表一个document，不同颜色的点代表不同的类，我们发现同类的document都集中在一起。当我要做搜寻的时候，输入一个查询词，就把query也通过这个encoder，变成一个二维的vector，然后看这个vector落在那个聚类里。auto-encoder的结果是非常惊人的，如果我们用LSA的话，得不到类似的结果。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/9.png" alt="9"></p>
<h1 id="Auto-encoder-——-Similar-Image-Search"><a href="#Auto-encoder-——-Similar-Image-Search" class="headerlink" title="Auto-encoder —— Similar Image Search"></a>Auto-encoder —— Similar Image Search</h1><p>Auto-encoder也可以用在image的搜寻上面。以图找图，最简单的方式，就是拿一张image的query，计算跟其他database里面的image的相似程度。比如可以算他们在pixel上面的相似程度，得到最像的几张就是要retrieve的结果。如果只是这么做的话，在pixel-wise上做比较，其实得不到太好的结果。我们用Michael Jackson的照片算它和database里面其他image的相似度，找出来最像的照片如下，</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/10.png" alt="10"></p>
<p>可以用deep auto-encoder把每一张image变成一个code，然后在code上面再去做搜寻。而且，因为今天做这件事情是unsupervised，所以要collect多少data都行。如下图，input一个$32\times 32$image，用RGB表示就是$32\times 32 \times 3$维，最后用一个256维的vector来表示这张image。然后把这个code通过另外一个decoder，再变回原来的image。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/11.png" alt="11"></p>
<p>reconstruct的结果如下：</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/12.png" alt="12"></p>
<p>如果不是在Pixel上面算相似度，而是在code上算相似度的话，就会得到比较好的结果。还是用Michael Jackson的image当作input,这次找到的都是人脸。虽然这些image在pixel level上看起来是不像的，但是通过很多hidden layer，把它转换成code的时候，在那个256维的空间是，它们是很像的。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/13.png" alt="13"></p>
<h1 id="Auto-encoder-——-Pre-training-DNN"><a href="#Auto-encoder-——-Pre-training-DNN" class="headerlink" title="Auto-encoder —— Pre-training DNN"></a>Auto-encoder —— Pre-training DNN</h1><p>Auto-encoder还可以用在pre-training上面，我们知道在train一个neural network的时候，有时候会烦恼怎么做参数initialization，有没有一些方法可以让我们找到一组比较好的initialization。这种找比较好的initialization的方法，就叫做pre-training。</p>
<p>假设现在要做MNIST的recognition，input是784维，output是10维，如下。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/14.png" alt="14"></p>
<p>在做pre-train的时候，先train一个auto-encoder，如下图，它input 784维，然后中间有个1000维的vector，然后再变回784维，希望input与output越接近越好。但是做这件事情的时候，需要稍微小心一点，因为我们在做auto-encoder的时候会希望code比dimension还要小，如果比dimension还要大，network可能就不会learn了，它只需要把原来的784维记住，放到1000维里面去，然后再解回来，就结束了。它会learn一个接近identity的matrix。所以如果hidden layer比input还要大的时候，需要加一个很强的regularization，比如对这1000维的output做L1的regularization，希望这1000维的output是sparse（这1000维里只有某几维有值，其他都是0）。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/15.png" alt="15"></p>
<p>那我们现在先learn了一个auto-encoder，learn好以后，我们把784维到1000维的这个weight $W^1$保留下来，然后fix住它，接下来把所有database里面的digit通通变成1000维的vector。接下来，再learn另一个auto-encoder，它把1000维的vector变成1000维的code,然后再转回1000维的vector,learn这样的auto-encoder，让input与output越接近越好。然后把$W^2$也保存下来。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/16.png" alt="16"></p>
<p>接下来fix住$W^2$的值，再learn第三个auto-encoder，learn好这个auto-encoder，得到它的weight $W^3$，再把$W^3$保留下来。接下来，$W^1$,$W^2$,$W^3$等于是再learn整个neural network的时候的initialization，最后再random initialize最后500到10维的weight，再用back propagation去调一遍，我们称这个步骤为fine tune，因为$W^1$,$W^2$,$W^3$都已经是很好的weight了。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/17.png" alt="17"></p>
<p>Pre-training在过去如果要learn一个很deep的neural network的话可能是需要的，不过现在training的技术进步后，基本上network不用pre-training。但是pre-training有个妙用就是，如果今天有很多unlabeled data但只有少量labeled data，可以用大量的unlabeled data去把$W^1$,$W^2$,$W^3$先initialize好，那最后的labeled data就只需要稍微调整weight就好。所以pre-training这招在有大量unlabel data的时候还是有用的。</p>
<h1 id="De-noising-auto-encoder"><a href="#De-noising-auto-encoder" class="headerlink" title="De-noising auto-encoder"></a>De-noising auto-encoder</h1><p>有个方法可以让auto-encoder做的更好，叫<strong>De-noising auto-encoder</strong>，它的概念其实很简单。把原来的input $x$加上一些noise变成$x^{\prime}$，然后把$x^{\prime}$ encode以后变成code $c$，再把$c$ decode回来变成$y$。要注意的是，现在的要让output与加了noise之前的input越接近越好。如果有做这件事情，learn出来的结果会比较robust，因为encoder现在不只learn到encode这件事，还learn到了把杂讯过滤掉这件事。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/18.png" alt="18"></p>
<p>还有另外一招叫做<strong>Contractive auto-encoder</strong>。我们在learn code的时候，加上一个constrain，这个constrain是当input有变化的时候对这个code的影响是被minimize的。这件事情其实很像de-noising auto-encoder，只是从不同的角度来看。de-noising auto-encoder是说加了noise以后，还要再reconstruct回原来没有noise的结果。Contractive auto-encoder是希望当input变了，也就是加了noise以后，对这个code的影响是小的。它们做的事情其实是很类似的。</p>
<p>另外还有很多non-linear dimension reduction的方法，比如<strong>Restricted Boltzmann Machine</strong>（它其实不是neural network）和<strong>deep belief network</strong>（不是neural network），它们其实都是graph co-model。</p>
<h1 id="Auto-encoder-for-CNN"><a href="#Auto-encoder-for-CNN" class="headerlink" title="Auto-encoder for CNN"></a>Auto-encoder for CNN</h1><p>如果我们今天要处理的对象是image的话，我们知道要用CNN。CNN在处理image的时候会有一些convolution layers和pooling layers，用convolution layers和pooling layers交替，让image变得原来越小，最后去做flatten。</p>
<p>今天如果是做auto-encoder的话，不只要有个encoder，还要有decoder。如果encoder的部分是做convolution与pooling交替操作，理论上decoder应该就是做跟encode相反的事情，如下图。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/19.png" alt="19"></p>
<p>那么这个unpooling和deconvolution它们是什么呢？</p>
<h2 id="CNN-Unpooling"><a href="#CNN-Unpooling" class="headerlink" title="CNN - Unpooling"></a>CNN - Unpooling</h2><p>pooling的操作如下，现在得到一个$4\times 4$的matrix，接下来把matrix里面pixel分成4个一组，从每组里面挑一个最大的。当如果要做unpooling的话，要做另一件事情，要记得刚刚在做pooling是从哪里取值，然后再做unpooling的时候，要把原来比较小matrix扩大，比如之前记得在做pooling的时候是从左上角pool值，unpooling的时候就把值放到左上角，其他不零。其实这不是unpooling唯一的做法，在keras里面做法是不一样的，它是直接repeat那些value，也是就不用去记之前pooling的位置。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/20.png" alt="20"></p>
<h2 id="CNN-Deconvolution"><a href="#CNN-Deconvolution" class="headerlink" title="CNN - Deconvolution"></a>CNN - Deconvolution</h2><p>事实上，Deconvolution就是convolution，我们来解释一下这件事情。我们举一维的convolution（方便起见）当作例子，假设input有5个dimension，filter size为3，我们就把input的3个value分别乘上3个weight，得到一个output，再把这个filter shift一格，把3个value分别乘上3个weight得到下一个output，依次类推，这是convolution的操作。convolution是从3个值变为1个值，deconvolution应该是从1个值变为3个值，那么我们可以让一个值分别乘上3个weight变成3个值，重叠的地方就加起来。事实上，这件事情等同于是在做convolution，相当于input是3个value，我们把它做padding，旁边补零，检查两个方框里面output的5个值，不难发现它们其实是一样的。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/21.png" alt="21"></p>
<p>如果把convolution和deconvolution比较，他们的不同点在哪里？不同点在于它们的weight是相反的，如上图中，最左边是weight顺序是红蓝绿，最右边是绿蓝红。但它们做到operation一样都是convolution。所以在keras里面，根本不需要另外再写一个deconvolution的layer，</p>
<h1 id="Sequence-to-sequence-Auto-encoder"><a href="#Sequence-to-sequence-Auto-encoder" class="headerlink" title="Sequence-to-sequence Auto-encoder"></a>Sequence-to-sequence Auto-encoder</h1><p>上面的auto-encoder，它的input通通都是fix-length的vector。但是很多东西，本质上不应该把它表示成vector，比如语音。一段声音讯号有长有短，它不是一个vector,一段文章有长有短也不是一个vector。虽然可以用bag-of-word把它变成一个vector，但这个方法会失去词汇和词汇之间的前后关系，这个是不好好。</p>
<p>具体的<strong>Sequence-to-sequence Auto-encoder</strong>到RNN的时候再讲。</p>
<h1 id="Other-application"><a href="#Other-application" class="headerlink" title="Other application"></a>Other application</h1><p>我们之前用encoder把原来的image变成小的dimension，但我们同时也train了decoder，这个decoder其实是有妙用的，可以拿decoder来产生新的image。也就是说把learn好的decoder拿出来，然后给他一个random的input number，他的output希望就是一张图。这件事情做起来其实是相当容易的，下面是用MNIST来train的结果，把784维的一个image通过一个hidden layer然后project到二维。再把二维通过一个hidden layer解回原来的image。在encoder部分，二维的vector画出来如下图左边，不同颜色的点代表不同的数字，然后接下来在红色的框框里等间隔的去sample一个二维的vector出来，然后把二维的vector丢到NN decoder里面，让它output一个image出来。这些二维的vector不见得是某个image compress以后的结果，它不见得原来有对应的image，它就是某个二维的vector，然后丢到decoder以后，看看它可以产生什么。我们发现在下图中红色框框内等距离做sample，得到的结果如右边所示，可以看到左上角比较差，因为它在红色方框内其实是没有image（input image的时候不会对应到这里），这个区域的vector sample出来，通过decoder解回来不是image，看起来怪怪的。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/22.png" alt="22"></p>
<p>那我们怎么知道要sample在哪个地方？因为我们必须先观察一下二维vector的分布，才能知道哪边是有值的，这样sample出来才比较有可能是一个image，<br>如果sample出来的是上图蓝色方框区域，那么得到的东西大概率不是一个image。但是要先分析二维的code分布感觉有点麻烦，那要怎么确保我们希望的region里面都是image？有一个很简单的做法就是在code上面加上regularization，在code上面直接加L2的regularization，让所有的node都比较接近0，接下来就在0附近sample，这样就比较有可能sample出来的vector都可以对应到数字。这样做的结果如下图，可以看到train出来的code都会集中在接近0的地方。接下来就以0为中心，然后等距离在红框内sample image，结果如下图右边，从这里可以观察到很多有趣的现象，例如从左到右横轴代表的是有没有圆圈，纵轴可能是表示倾斜程度。所以不只可做encoder，还可以用code来画image，这个image并不是从原来image database sample出来的，它是machine自己画出来的。</p>
<p><img src="/2019/11/05/Unsupervised Learning Auto-encoder/23.png" alt="23"></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://www.cs.toronto.edu/~hinton/science.pdf" target="_blank" rel="noopener">Reducing the Dimensionality ofData with Neural Networks</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/05/Unsupervised Learning Neighbor Embedding/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/05/Unsupervised Learning Neighbor Embedding/" itemprop="url">Unsupervised Learning —— Neighbor Embedding</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-05T12:50:31+08:00">
                2019-11-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Manifold-Learning"><a href="#Manifold-Learning" class="headerlink" title="Manifold Learning"></a>Manifold Learning</h1><p>我们知道，data point可能是高维空间里面的一个Manifold，也就是说，Data point其实是分布在一个低维空间里，只是被扭曲的塞到了一个高维空间里面。讲到Manifold的时候，常常举的例子就是“地球”，地球的表面就是一个Manifold，它是一个二维平面，但是被塞到三维空间里面。在一个Manifold里面，只有很近距离的点，Euclidean distance才会成立。所以，Manifold Learning要做的事情是把S形展开，把塞在高维空间里面的低维空间摊平，之后我们就可以在这个平面上用Euclidean distance来计算点和点之间的距离。这会对接下来如果要做clustering或者做supervised learning都是会有帮助的。</p>
<p><img src="/2019/11/05/Unsupervised Learning Neighbor Embedding/1.png" alt="1"></p>
<h1 id="Locally-Linear-Embedding-LLE"><a href="#Locally-Linear-Embedding-LLE" class="headerlink" title="Locally Linear Embedding(LLE)"></a>Locally Linear Embedding(LLE)</h1><p>在原来的空间里面，点的分布如下，对某一个点$x^i$，我们先选出$x^i$的neighbor $x^j$，接下来我们要找$x^i$与$x^j$的关系，它们的关系我们写作$w_{ij}$。</p>
<p><img src="/2019/11/05/Unsupervised Learning Neighbor Embedding/2.png" alt="2"></p>
<p>$w_{ij}$是怎么找出来的呢？我们假设每一个$x^i$，都可以用它的neighbor做linear combination以后，组合而成，那么$w_{ij}$就是拿$x^j$去组合$x^i$的时候的linear combination的weight。我们现在要找一组$w_{ij}$，这组$w_{ij}$对$x_i$的所有neighbor $x^j$做weighted sum的时候，他可以跟$x^i$越接近越好,即下面的式子越小越好。</p>
<p>$$\sum_i||x^i - \sum_jw_{ij}x^j||_2$$</p>
<p>接下来我们要做dimension reduction，把原来所有的$x^i$和$x^j$转成$z^i$和$z^j$。这里的原则是，从$x^i$和$x^j$转成$z^i$和$z^j$，它们中间的关系$w_{ij}$是不变的。</p>
<p><img src="/2019/11/05/Unsupervised Learning Neighbor Embedding/3.png" alt="3"></p>
<p>所以LLE做的事情是，首先$w_{ij}$在原来的space上找完以后，就不要去动它。接下来为每一个$x^i$和$x^j$找另外一个vector。我们现在要做dimension reduction，所以新找的vector要比原来的dimension还要小。$z^i$和$z^j$要minimize下面这个function:</p>
<p>$$\sum_i||z^i - \sum_jw_{ij}z^j||_2$$</p>
<p>也就是说，原来的$x^j$可以做linear combination产生$x^i$，$z^j$也可以做linear combination产生$z^i$。我们就是要找这组z可以满足$w_{ij}$给我们的constrain。所以上面的式子里面，$w_{ij}$变成已知的，我们要找一组$z$，让$z^j$通过$w_{ij}$做weighted sum以后，它可以跟$z^i$越接近越好。</p>
<p>注意，LLE并没有一个明确的function来告诉我们怎么做dimension reduction。不像我们在做Auto-Encoder的时候，learn出一个encoder的network，input一个新的datapoint,然后可以找到它dimension的结果。但是LLE里面并没有一个明确的function告诉我们怎么从$x$变到$z$。$z$就是完全凭空找出来的。</p>
<p>如果用LLE或其他类似的方法有一个好处，就算是原来的$x^i$、$x^j$不知道，只知道$w_{ij}$(不知道$x^i$、$x^j$要用什么vector来描述)，也可以用LLE这种方法。</p>
<p>LLE需要好好的调一下neighbor的个数，neighbor的数目要刚刚好才会得到好的结果。下面是原始的paper里面的图，可以发现$K$太小和太大,得出的结果都不会太好。为什么$K$太大结果也不太好呢？因为我们之前的假设，就是每一个Euclidean distance只是在很近的距离内，可以被这样想。所以，点和点之间关系，在transform前后可以被keep住，只有在距离很近的时候才能够成立。当$K$很大的时候，会考虑一些距离很远的点，会考虑transform以后relation没有办法keep住的点。</p>
<p><img src="/2019/11/05/Unsupervised Learning Neighbor Embedding/4.png" alt="4"></p>
<h1 id="Laplacian-Eigenmaps"><a href="#Laplacian-Eigenmaps" class="headerlink" title="Laplacian Eigenmaps"></a>Laplacian Eigenmaps</h1><p>我们之前在讲semi-supervised learning的时候，有讲过smoothness assumption，如果要比较两个点之间的距离，只算它的Euclidean distance是不够的，而要看它们在high density的region之间的distance。如果两个点之间有high density的connection，那它们才是真正接近的。</p>
<p>这件事情我们可以用一个Graph来描述，也就是把data point construct成一个graph，算data point两两之间的相似度，如果相似度超过一个threshold，就把它们connect起来。而建一个graph的方法有很多。</p>
<p>把点变成graph以后，考虑smoothness的距离就可以被这个graph上面的connection来approximate。在之前的semi-supervised learning有讲过，如果$x^1$和$x^2$z在high density的region相近，那他们的label $\hat{y}^1$和$\hat{y}^2$有可能是一样的。同样的道理可以被apply到unsupervised的test上面，如果$x^1$和$x^2$在high density的region是close的，我们希望$z^1$和$z^2$他们也是相近的。找到$z^i$和$z^j$去minimize下面$S$的值。</p>
<p>$$S = \frac{1}{2}\sum_{i,j}w_{i,j}||(z^i - z^j)||_2$$</p>
<p>上面的做法是有问题的，因为我们总可以将$z^i$和$z^j$的值通通设为0，所以光有上面的式子是不够的。所以我们需要给$z$一些constrain。</p>
<p>如果$z$降维以后的空间是$M$维空间，那我们不会希望$z$还分布在一个比$M$还小的dimension里面，即：</p>
<p>if the dim of $z$ is $M$, $Span\{z^1,z^2,\cdots,z^N\} = R^M$</p>
<p>有了这个constrain，上面的式子解出来的$z$跟我们前面看到的那个graph laplacian L是有关系的，他其实就是graph laplacian的eigenvector。所以它叫做<strong>Laplacian Eigenmaps</strong>,因为我们找的是laplacian matrix的eigenvetor。</p>
<p>我们我们先找出$z$以后，再去做cluster（K-means），这一招叫做spectral clustering。</p>
<h1 id="t-SNE"><a href="#t-SNE" class="headerlink" title="t-SNE"></a>t-SNE</h1><p><strong>t-SNE</strong>是<strong>T-distribution Stochastic Neighbor Embedding</strong>的缩写。前面的方法有一个最大的问题就是，它只假设相近的点应该要是接近的，而没有假设不相近的点要分开(Similar data are close,but different data may collapse)。所以比如说用LLE在MNIST上，会遇到这样的情形：它确实会把相同class的点都聚集在一起（下图中不同的颜色表示不同的digit），但它没有防止不同的class的点不要叠成一团。 </p>
<p><img src="/2019/11/05/Unsupervised Learning Neighbor Embedding/6.png" alt="6"></p>
<p>做t-SNE一样是要做降维，把原来的data point $x$变成比较low dimension的vector $z$。在原来的$x$这个space上面，我们会计算所有的点的pair $x^i$和$x^j$之间的similarity $S(x^i,x^j)$。接下来，会做一个normalization，我们会计算：</p>
<p>$$P(x^j|x^i) = \frac{S(x^i,x^j)}{\sum_{k\neq i}S(x^i,x^k)}$$</p>
<p>另外假设我们今天已经找出了一个low dimension的representation就是$z^i$和$z^j$的话，我们也可以计算是$z^i$和$z^j$之间的similarity $S^{\prime}(z^i,z^j)$,一样计算：</p>
<p>$$Q(z^j|z^i) = \frac{S^{\prime}(z^i,z^j)}{\sum_{k\neq i}S^{\prime}(z^i,z^k)}$$</p>
<p>做这个normalization是必要的，因为我们不知道在高维空间算出来的距离$S(x^i,x^j)$与$S^{\prime}(z^i,z^j)$的scale是不是一样的。如果有做normalization，那最后就可以把他们都变成几率，它们的值介于0和1之间，它们的scale会是一样的。</p>
<p>现在我们还不知道$z^i$和$z^j$的值到底是多少，我们希望找一组$z^i$和$z^j$,让原来根据similarity在$S$这个原来的space算出来的distribution跟在dimension reduction以后的space算出来的distribution越接近越好。可以用<strong>KL divergence</strong>来衡量两个distribution之间的相似度。minimize下面的$L$,用gradient descent。</p>
<p>$$ L = \sum_iKL\left(P(\star|x^i)||Q(\star|z^i)\right)$$</p>
<p>有一个问题就是在做t-SNE的时候，会计算所有data point之间的similarity，运算量有点大。一个常见的做法是先做降维，比如原来的dimension很大，我们不会直接从很高的dimension直接做t-SNE,因为这样计算similarity的时间太长。通常会先用PCA做降维，比如降到50维，然后用t-SNE从50维降到2维。</p>
<p>像上面所讲到的这些方法，比如t-SNE，如果给他一个新的data point，它是没办法做的。它只能够已经先给他一大堆$x$，它帮你把每个$x$的$z$都找出来，但是找完这些$z$以后，在给他一个新的$x$，要再重新跑一边上面一整套演算法，很麻烦。所以一般t-SNE的作用比较不是用在这种training test的这种case上面，通常常用的拿来做visualization。如果已经有一大堆的$x$，它是high dimensional的，而我们想要visualize它们在二维空间的分布上是什么样子，用t-SNE往往可以得到不错的结果。</p>
<h2 id="t-SNE-——-Similarity-Measure"><a href="#t-SNE-——-Similarity-Measure" class="headerlink" title="t-SNE —— Similarity Measure"></a>t-SNE —— Similarity Measure</h2><p>t-SNE的一个有趣的地方是，t-SNE的similarity的选择是非常神妙的。我们在原来的data point的space上面，similarity选择RDF的function：</p>
<p>$$ S(x^i,x^j) = exp(-||x^i - x^j||_2) \tag{1}$$</p>
<p>之前有说如果要在graph上算similarity的话，用这种方法比较好，因为它可以确保只有非常相近的点才有值。因为exp掉的非常快，只要距离一拉开，similarity就会变得很小。</p>
<p>在t-SNE之前有一个方法叫做SNE，SNE是一个很直觉的想法，在data point原来的space上用式子(1)这个evaluation的measure，当然在新的space上选用同样的measure就好啊：</p>
<p>$$ S^{\prime}(z^i,z^j) = exp(-||z^i - z^j||_2) $$</p>
<p>但是t-SNE神妙的地方在于，它在dimension reduction以后的space，它选的measure跟原来的space是不一样的，它在dimension reduction以后选的space是t-distribution的其中一种(t-distribution里面的参数可以调他，可以产生很多种不同的distribution)。t-distribution的其中一种如下:</p>
<p>$$S^{\prime}(z^i,z^j) = 1/1 + ||z^i - z^j||_2$$</p>
<p>为什么要这么做呢？这里有一个很直觉的理由，下图中假设横轴代表了在原来space上的Euclidean distance或者是做dimension reduction以后的Euclidean distance，红色的线和蓝色线分别为$S(x^i,x^j)$和$S^{\prime}(z^i,z^j)$,从图中的两个点可以看到，如果本来距离比较近，它们的影响是比较小的，如果距离比较远，那从原来的distribution变到t-distribution以后，会被拉的很远。也就是说，原来在高维空间里面，如果距离很近，做完transform以后他还是很近，如果原来就已经有一段距离了，做完transform后就会被拉得很远。</p>
<p><img src="/2019/11/05/Unsupervised Learning Neighbor Embedding/7.png" alt="7"></p>
<p>所以t-SNE画出来的图往往如下，它会把data point聚集成一群一群的。因为data point之间本来只要有一个gap，做完t-SNE以后就会把gap强化，gap会变得特别明显。</p>
<p><img src="/2019/11/05/Unsupervised Learning Neighbor Embedding/8.png" alt="8"></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/11/04/Unsupervised Learning Word Embedding/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/11/04/Unsupervised Learning Word Embedding/" itemprop="url">Unsupervised Learning —— Word Embedding</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-11-04T19:48:19+08:00">
                2019-11-04
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p><strong>Word Embedding</strong>其实是Dimension Reduction的一个非常好的应用。</p>
<h1 id="introduction"><a href="#introduction" class="headerlink" title="introduction"></a>introduction</h1><p>如果我们今天要用一个vector来表示一个word，会怎么做呢?最典型的做法叫做<strong>1-of-N Encoding</strong>，每一个word，我们用一个vector来表示，这个vector的dimension就是这个世界上可能有的word数目。每个word对应到其中一维，例如下图中apple就是第一维是1，其他都是0。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/1.png" alt="1"></p>
<p>如果用这种方式来描述一个word，那么这个vector一点都不informative。每一个word它的vector都是不一样的，所以从这个vector里面，没有办法得到任何咨询。例如没有办法知道dog和cat都是动物这件事。怎么办呢？有一个方法就是建<strong>Word Class</strong>，把有同样性质的word把它们cluster成一群一群的，然后就用那个word所属的class来表示这个word。这就是我们之前做Dimension Reduction的时候讲的clustering的概念。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/2.png" alt="2"></p>
<p>但是光用class是不够的，我们之前有讲过光做clustering是不够的，因为如果光做clustering的话，我们会少了一些information。比如说上面class 1和class 3都是属于生物，但是在class里面没有办法呈现这一件事。为解决这个问题，我们就需要<strong>word Embedding</strong>。</p>
<p>word Embedding是把每一个word都project到一个high dimensional的space上面，虽然这里说这个space是high dimensional，但是它远比1-of-N encoding的dimension要低。从1-of-N encoding到Word Embedding，这是Dimension Reduction的process。我们希望在word Embedding的这个图上，我们可以看到的结果是，类似语义的词汇，它们在这个图上是比较接近的。而且在high dimensional space里面，每个dimension可能都有它特别的含义。比如，假设我们现在做完word embedding以后，每一个word的word Embedding的feature vector如下图，那么可能就可以知道，横轴的dimension代表了生物和其他东西之间的差别，纵轴的dimension可能就代表了与运动有关的东西。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/3.png" alt="3"></p>
<h1 id="word-Embedding"><a href="#word-Embedding" class="headerlink" title="word Embedding"></a>word Embedding</h1><p>怎么做word Embedding呢？word Embedding是一个unsupervised approach，也就是我们通过让machine阅读大量的文章，它就可以知道每一个词汇它的embedding的feature vector应该长什么样子。</p>
<p>这是一个unsupervised的problem，因为我们要做的事情就是learn一个Neural Network，找一个function，input是一个词汇，output就是那一个词汇所对应的word embedding的那一个vector。而我们手上有的training data就是一大堆文字，即我们只有input没有output。这个问题要怎么解呢？我们之前有讲过一个deep learning base的Dimension Reduction方法叫做<strong>auto-encoder</strong>，learn一个network，让它的输入等于输出，把某一个hidden layer拿出来，就是Dimension Reduction的结果。那么这个地方可以用Auto-encoder吗？</p>
<p>这里其实没办法用Auto-encoder来解。想想看，如果用1-of-N encoding当作它的input，对1-of-N encoding来说，每个词汇都是independent,把这样子的vector做Auto-encoder，其实没有办法learn出任何informative的information。所以在word enbedding这个task里面用auto-encoder是没有办法的。如果input是1-of-N encoding用Auto-encoder是没有办法的，除非用character的n-gram来描述一个word，或许它可以抓到一个字首、字根的含义。不过基本上大家现在不这么做。</p>
<p>那要如何找word embedding呢？要如何了解一个词汇的含义呢？要看这个词汇的context。每一个词汇的含义，可以根据它的上下文来得到。</p>
<ul>
<li><p>Machine learn the meaning of words from reading a lot of documents without supervision</p>
</li>
<li><p>A word can be understood by its context</p>
</li>
</ul>
<h2 id="How-to-exploit-the-context"><a href="#How-to-exploit-the-context" class="headerlink" title="How to exploit the context"></a>How to exploit the context</h2><p>怎么通过上下文来找出word Embedding的vector呢？有两个不同体系的做法。</p>
<h3 id="Count-based"><a href="#Count-based" class="headerlink" title="Count based"></a>Count based</h3><p><strong>Count based</strong>的方法是说，如果我们现在有两个词汇$w_i$和$w_j$，它们常常在同一篇文章中出现，那么它们的word vector(用$V(w_i)$、$V(w_j)$表示)会比较接近。这种方法一个很有代表性的例子叫做<strong>Glove vector</strong>，参考链接1。</p>
<p>这个方法的原则是，假设我们知道$V(w_i)$和$V(w_j)$，那么我们可以计算它们的inner product。假设$N_{i,j}$是$w_i$与$w_j$它们co-occur在同样的document里面的次数，那么我们希望为$w_i$找到一组vector，为$w_j$也找到一组vector，然后希望$V(w_i)\cdot V(w_j)$与$N_{i,j}$越接近越好。这和我们之前讲的matrix factorization的概念是一样的。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/4.png" alt="4"></p>
<h3 id="Prediction-based"><a href="#Prediction-based" class="headerlink" title="Prediction based"></a>Prediction based</h3><p><strong>Prediction based</strong>的想法是，我们来learn一个neural network，它做的事情是prediction。这个neural network做的事情是given前一个word $w_{i-1}$，predict下一个可能出现的word是谁。</p>
<p>我们知道每一个word，都用1-of-N encoding，可以把它表示成一个feature vector。所以，如果我们要做prediction这件事情的话，我们就是要learn一个neural network，它的input就是$w_{i-1}$的1-of-N encoding的feature vector，它的output就是下一个word $w_i$是某一个word的几率。也就是说，这个model它的output的dimension就是vector的size，假设现在世界上有10万个word,output就是10万维。每一维代表某一个word是会被当作$w_i$的几率。假设这就是一个我们所熟知的multi-layer的perceptron，一个deep neural network。把input feature vector丢进去的时候，它会通过很多hidden layer，然后我们会得到output。接下来，我们把第一个hidden layer的input拿出来（写作$\bf{Z}$），我们用$\bf{Z}$就可以代表一个word。input不同的1-of-N encoding，$\bf{Z}$就会不一样。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/5.png" alt="5"></p>
<p>为什么用prediction based的方法，就恩可以得到这样的vector呢？prediction based的方法是怎么体现根据一个词汇的上下文来了解一个词汇的含义这件事情呢？</p>
<p>假设我们的training data里面有一个文章，它里面有下面两句话。在第一个句子里面，蔡英文是$w_{i-1}$，宣誓就职是$w_i$。在另一个句子里面，马英九是$w_{i-1}$，宣誓就职是$w_i$。那我们在训练这个prediction model的时候，不管是input蔡英文还是马英九的1-of-N encoding，都会希望learning出来的结果是宣誓就职的几率比较大。蔡英文和马英九虽让是不同的input，但为了要让最后在output的地方得到一样的output，我们就必须让中间的hidden layer做一些事情，中间的hidden layer必须要学到这两个不同的词汇需要通过参数的转换以后把它们对应到同样的空间。在input进入hidden layer之前，必须把它们对应到接近的空间，这样我们在最后output的时候，它们才能有同样的几率。所以，当我们learn一个prediction model的时候，考虑一个word的context这一件事情，就自动被考虑在prediction model里面。所以把prediction model的第一个hidden layer拿出来，就可以得到我们想要找的这种word embedding的特性。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/6.png" alt="6"></p>
<h3 id="Prediction-based-——-Sharing-parameters"><a href="#Prediction-based-——-Sharing-parameters" class="headerlink" title="Prediction-based —— Sharing parameters"></a>Prediction-based —— Sharing parameters</h3><p>如果只用$w_{i-1}$去predict$w_i$，好像太弱了。只通过一个词汇去预测下一个词，对人来说也是比较难的。我们可以拓展这个问题，比如希望machine learn的是input前面两个词汇，然后predict下一个word。可以轻易的把这个Model扩展到N个词汇。一般我们如果真得要learn这样的word vector的话，通常input可能至少10个词汇。下面是input 2个word作为例子，可以轻易的将它扩展到10个word。</p>
<p>要注意的是，本来如果是一般的neural network，就把input $w_{i-2}$和$w_{i-1}$的1-of-N encoding的vector接在一起，变成一个很长的vector，直接丢到neural network里面当作input就可以了。但是实际上你在做的时候，会希望和$w_{i-2}$相连的weight跟$w_{i-1}$相连的weight它们是被tie在一起的，即$w_{i-2}$的第一个dimension跟第一个hidden layer的第一个neuron它们中间连的weight，和$w_{i-1}$的第一个dimension和第一个hidden layer的第一个neuron它们之间连的weight，这两个weight必须是一样的。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/7.png" alt="7"></p>
<p>这么做的一个显而易见的理由是，如果我们不这么做，把同一个word放在$w_{i-2}$的位置跟放在$w_{i-1}$的位置，通过transform以后，得到的embedding就会不一样。另外一个理由是这样可以减少参数量，因为input这个dimension很大，可能是10万维。</p>
<p>现在，假设$w_{i-2}$的1-of-N encoding就是$\bf{x_2}$，$w_{i-1}$的1-of-N encoding就是$\bf{x_1}$，它们的长度都是$|V|$。hidden layer的input我们把它写成一个vector $\bf{z}$，$\bf{z}$的长度是$|Z|$，那么有如下的式子</p>
<p>$$ \bf{z = W_1x_{i-2} + W_2x_{i-1}} $$</p>
<p>其中$\bf{W_1}$和$\bf{W_2}$都是一个$|Z|\times |V|$的matrix，这里我们强制</p>
<p>$$\bf{W_1 = W_2 = W}$$</p>
<p>所以有：</p>
<p>$$\bf{z = W(x_{i-2} + x_{i-1})}$$</p>
<p>通过上式我们可以得到一个word的vector。</p>
<p>这里会有一个问题，就是我们在实作上，怎么让$\bf{W_1}$跟$\bf{W_2}$它们的weight一定都要一样呢？事实上，我们在train CNN的时候，也有一样类似的问题。做法如下，假设我们现在有两个weight $w_i$和$w_j$，希望$w_i$和$w_j$是一样的。首先，给$w_i$和$w_j$一样的initialization，接下来，然后计算：</p>
<p>$$w_i \leftarrow w_i - \eta \frac{\partial C}{\partial w_i} - \frac{\partial C}{\partial w_j}$$  $$w_j \leftarrow w_j - \eta \frac{\partial C}{\partial w_j} - \frac{\partial C}{\partial w_i}$$</p>
<p>以上的式子可以确保$w_i$和$w_j$在训练的过程中永远都是tie在一起的。</p>
<h3 id="Prediction-based-——-Training"><a href="#Prediction-based-——-Training" class="headerlink" title="Prediction based —— Training"></a>Prediction based —— Training</h3><p>要如何训练这个network呢？这个network的训练完全是unsupervised的。也就是说，我们只要collect一大堆文字的data（可通过爬虫获取），然后通过Minimizing cross entropy去train你的model。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/8.png" alt="8"></p>
<h3 id="Prediction-based-——-Various-Architectures"><a href="#Prediction-based-——-Various-Architectures" class="headerlink" title="Prediction-based —— Various Architectures"></a>Prediction-based —— Various Architectures</h3><p>上面所讲的只是最基本的形态，其实这个prediction based的model可以有种种的变形，它们的performance在不同的task上互有胜负，所以很难说哪一种方法一定是比较好的。</p>
<ul>
<li><strong>Continuous bag of word (CBOW) model</strong></li>
</ul>
<p>之前所讲的都是拿前面的词汇去predict接下来的词汇，而CBOW是拿某一个词汇的context去predict中间的词汇（用$w_{i-1}$和$w_{i+1}$去predict $w_i$）。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/9.png" alt="9"></p>
<ul>
<li><strong>Skip-gram</strong></li>
</ul>
<p>Skip-gram是拿$w_i$去predict $w_{i-1}$和$w_{i+1}$。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/10.png" alt="10"></p>
<p>有人可能会问，这个network它不是deep的啊，它其实就是一个linear的hidden layer，不是deep的，为什么呢？</p>
<p>propose word vector的作者Tomas Mikolov有自己的解释：首先他并不是第一个propose word vector的人，在他之前其实就有很多人做过word vector，有提出类似的概念。Tomas Mikolov想要verify的最重要的一件事情就是，过去其他人其实就是用deep的，其实这个task不用deep就做得起来，不用deep的好处是减少运算量，可以跑很大量的data。过去确实有人做过word vector这件事，只是结果没有红起来。其实word embedding这个概念在语言界，大概是2010年的时候开始红起来，那个时候它叫做continuous的language model。一开始的时候，也不是用neural network来得到这个word embedding的，因为neural network的运算量很大，而是用其他比较简单的方法来得到word embedding。只是后来大家逐渐发现用neural network得到的结果才是最好的，过去没用neural network的方法逐渐式微，通通都变成neural network based的方法了。</p>
<hr>
<p>word vector可以得到一些有趣的特性，如果把同样类型的word vector摆在一起，比如下图中的(Italy-Rome,Germany-Berlin)，会发现它们之间是有某种固定的关系的。或者把同一个动词的三态摆在一起，它们也是有某种固定的关系。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/11.png" alt="11"></p>
<p>所以从word vector里面，可以发现我们不知道的word与word之间的关系。比如，有人发现如果把word vector两两相减，然后project到一个2维的space上面，会发现在某个区域，某一个word是包含于某一个word之间的关系，如下图：</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/12.png" alt="12"></p>
<p>所以用word vector的概念，我们可以做一些简单的推论。举例来说，有些word vector的差会很接近，如下</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/13.png" alt="13"></p>
<p>那如果有人问Rome之于Italy，就好像是Berlin至于什么，机器就可以回答这种问题了。因为由上面的式子我们知道</p>
<p>$$V(Germany) \approx V(Berlin) - V(Rome) + V(Italy)$$</p>
<h2 id="Multi-lingual-Embedding"><a href="#Multi-lingual-Embedding" class="headerlink" title="Multi-lingual Embedding"></a>Multi-lingual Embedding</h2><p>word vector还可以做很多其他的事情，比如把不同语言的word vector拉在一起。如果今天有一个中文的corpus和英文的corpus，我们各自分别去train一组word vector，会发现中文和英文的word vector它是完全没有任何关系的，它们每一个dimension对应的含义并没有任何关系，为什么？因为要train word vector的时候，它凭借的就是上下文之间的关系，所以如果corpus里面没有中文英文的句子混杂在一起，那machine就没法判断中英文之间的关系。但是假如我们已经事先知道某几个中文词汇和英文词汇是对应在一起的，先得到一组中文的vector,再得到一组英文的vector，接下来可以再learn一个model，它把中文和英文对应的词汇project在space上的同一个点。做了这个transform以后，接下来又有新的中文和英文词汇，通可以用同样的projection把它们project到同一个space上面，这样就能做到类似自动翻译的效果。</p>
<h2 id="Multi-domain-Embedding"><a href="#Multi-domain-Embedding" class="headerlink" title="Multi-domain Embedding"></a>Multi-domain Embedding</h2><p>embedding不只限于文字，也可以对影像对embedding。下面是一个例子，如下图，我们先已经找到一组word vector（cat,horse,dog等等）。接下来，要learn一个model，它的input是一张image，output是一个跟word vector一样dimension的vector。假设一些image我们已经知道是属于哪一类了，那可以把它们project到它们所对应到的word vector附近。当又有一个新的image进来，我们就可以通过同样的project，把它project到这个space上以后，神奇的是会发现它可能就在猫的附近，machine就会告诉我们这张image是猫。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/14.png" alt="14"></p>
<p>在做影像分类的时候，machine其实很难去处理新增加的、它没有办法看过的object。比如我们先定好10个class，那么learn出来的model，就是只能分这10个class。如果今天有一个新的东西不在这10个class里面，那么model是完全无能为力的。但是如果用上面的方法，就算有一张image，是在train的时候没有看过的class，比如cat，但是如果cat的image可以project到cat的vector附近的话，就会知道这张image叫做cat。这就好像是machine先阅读了大量的文章以后，它知道每一个词汇指的是什么意思，接下来在看image的时候，它就可以根据它已经阅读得到的知识，去mapping每一个image所应该对应的东西。这样就算它看到它没有看过的东西，它也可能叫出它的名字。</p>
<h2 id="Document-Embedding"><a href="#Document-Embedding" class="headerlink" title="Document Embedding"></a>Document Embedding</h2><p>也可以做<strong>Document Embedding</strong>，不只是把一个word变成一个vector，也可以把一个document变成一个vector。</p>
<p>最简单的方法就是把一个document变成bag-of-word，然后用Auto-encoder就可以learn出这个document的Semantic Embedding。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/15.png" alt="15"></p>
<p>但是光用bag-of-word来描述一篇document是不够的，因为我们知道词汇的顺序代表了很重要的含义。同样的bag-of-word在语义上可能是完全不一样的。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/16.png" alt="16"></p>
<p>要解决这个问题，可以参考下面的reference。</p>
<p><img src="/2019/11/04/Unsupervised Learning Word Embedding/17.png" alt="17"></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><p><a href="https://nlp.stanford.edu/projects/glove/" target="_blank" rel="noopener">GloVe: Global Vectors for Word Representation</a></p>
</li>
<li><p><a href="https://www.semanticscholar.org/paper/Efficient-Estimation-of-Word-Representations-in-Mikolov-Chen/330da625c15427c6e42ccfa3b747fb29e5835bf0" target="_blank" rel="noopener">Efficient Estimation of Word Representations in Vector Space</a></p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/30/blog01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/30/blog01/" itemprop="url">blog01</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-30T19:43:08+08:00">
                2019-10-30
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/C/" itemprop="url" rel="index">
                    <span itemprop="name">C++</span>
                  </a>
                </span>

                
                
                  ， 
                
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/C/CMake/" itemprop="url" rel="index">
                    <span itemprop="name">CMake</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h1 id="Global-varibales"><a href="#Global-varibales" class="headerlink" title="Global varibales"></a>Global varibales</h1><ul>
<li><p><code>CMAKE_BINARY_DIR</code> : if you are building in-source, this is the same as <code>CMAKE_SOURCE_DIR</code>, otherwise this is the top level directory of your build tree</p>
</li>
<li><p><code>CMAKE_SOURCE_DIR</code> : this is the directory, from which cmake was started, i.e. the top level source directory</p>
</li>
<li><p><code>EXECUTABLE_OUTPUT_PATH</code> : set this variable to specify a common place where CMake should put all executable files (instead of <code>CMAKE_CURRENT_BINARY_DIR</code>)</p>
  <figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span>(EXECUTABLE_OUTPUT_PATH <span class="variable">$&#123;PROJECT_BINARY_DIR&#125;</span>/bin)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>LIBRARY_OUTPUT_PATH</code> : set this variable to specify a common place where CMake should put all libraries (instead of <code>CMAKE_CURRENT_BINARY_DIR</code>)</p>
  <figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SET</span>(LIBRARY_OUTPUT_PATH <span class="variable">$&#123;PROJECT_BINARY_DIR&#125;</span>/lib)</span><br></pre></td></tr></table></figure>
</li>
<li><p><code>PROJECT_NAME</code> : the name of the project set by <code>PROJECT()</code> command.</p>
</li>
</ul>
<ul>
<li><code>PROJECT_SOURCE_DIR</code> : contains the full path to the root of your project source directory, i.e. to the nearest directory where <code>CMakeLists.txt</code> contains the <code>PROJECT()</code> command. Now, you have to compile the <code>test.cpp</code>. The way to do this task is too simple. Add the following line into your <code>CMakeLists.txt</code>:</li>
</ul>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">add_executable</span>(hello <span class="variable">$&#123;PROJECT_SOURCE_DIR&#125;</span>/<span class="keyword">test</span>.cpp)</span><br></pre></td></tr></table></figure>

<h1 id="example"><a href="#example" class="headerlink" title="example"></a>example</h1><p>source code of <code>test.cpp</code></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">     <span class="built_in">cout</span> &lt;&lt; <span class="string">"Hello World"</span> &lt;&lt; <span class="built_in">endl</span>;</span><br><span class="line"></span><br><span class="line">     <span class="keyword">return</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<p>CMakeLists.txt</p>
<figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Specify the minimum version for CMake</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">cmake_minimum_required</span>(VERSION <span class="number">2.8</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Project's name</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">project</span>(hello)</span><br><span class="line"><span class="comment"># Set the output folder where your program will be created</span></span><br><span class="line"><span class="keyword">set</span>(CMAKE_BINARY_DIR <span class="variable">$&#123;CMAKE_SOURCE_DIR&#125;</span>/bin)</span><br><span class="line"><span class="keyword">set</span>(EXECUTABLE_OUTPUT_PATH <span class="variable">$&#123;CMAKE_BINARY_DIR&#125;</span>)</span><br><span class="line"><span class="keyword">set</span>(LIBRARY_OUTPUT_PATH <span class="variable">$&#123;CMAKE_BINARY_DIR&#125;</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># The following folder will be included</span></span><br><span class="line"><span class="keyword">include_directories</span>(<span class="string">"$&#123;PROJECT_SOURCE_DIR&#125;"</span>)</span><br></pre></td></tr></table></figure>


          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/28/blog02/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/28/blog02/" itemprop="url">Vim基础</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-28T12:13:54+08:00">
                2019-10-28
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>所用系统为Ubuntu 16.04LTS</p>
<h1 id="使用h-j-k-l来移动光标"><a href="#使用h-j-k-l来移动光标" class="headerlink" title="使用h j k l来移动光标"></a>使用h j k l来移动光标</h1><p>vim中不使用方向键来移动光标是因为在vim诞生的时候，那时的键盘上还没有方向键。</p>
<h1 id="插入模式即退出"><a href="#插入模式即退出" class="headerlink" title="插入模式即退出"></a>插入模式即退出</h1><p>vi最具特色的功能就是支持多种模式，并且可以在这些模式之间进行自由切换以实现它的强大功能。vi有6种基本模式和5种派生模式。</p>
<ul>
<li><p>基本模式</p>
<ul>
<li>普通模式</li>
<li>插入模式</li>
<li>可视模式</li>
<li>选择模式</li>
<li>命令行模式</li>
<li>Ex模式</li>
</ul>
</li>
<li><p>派生模式</p>
<ul>
<li>操作符等待模式</li>
<li>插入普通模式</li>
<li>插入可视模式</li>
<li>插入选择模式</li>
<li>替换模式</li>
</ul>
</li>
</ul>
<h2 id="插入模式"><a href="#插入模式" class="headerlink" title="插入模式"></a>插入模式</h2><p>使用vi打开名为lesson2的文本文件，命令如下</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ vi lesson2</span><br></pre></td></tr></table></figure>

<p>打开之后默认进入的是普通模式。普通模式下可以使用<code>h j k l</code>来移动光标（当然使用方向键来移动也可以）。这个时候敲一下键盘<code>i</code>键，会发现左下角出现<strong>INSERT</strong>字样。点击<code>Esc</code>键可以退出insert模式。</p>
<p>事实上进入插入模式的方式有很多，如下，它们的区别主要是进入的时候光标到 位置不同。</p>
<p><img src="/2019/10/28/blog02/1.png" alt="1"></p>
<h2 id="退出vim"><a href="#退出vim" class="headerlink" title="退出vim"></a>退出vim</h2><p>退出有两种方式，一种是<strong>保存修改并退出</strong>，一种是<strong>忽略修改直接退出</strong>。</p>
<p>忽略修改直接退出比较简单，首先按下冒号，进入命令行模式，然后输入<code>q!</code>即可。</p>
<p>保存修改并退出，按下冒号进入命令行模式，然后输入<code>wq</code>即可。</p>
<h2 id="删除命令"><a href="#删除命令" class="headerlink" title="删除命令"></a>删除命令</h2><p>可以在<strong>插入模式</strong>里面使用退格键来删除光标前面的字符，或者使用del键来删除光标指定的字符。</p>
<p>在<strong>普通模式</strong>下，有如下删除方法：</p>
<ul>
<li><p>删除一个字符可以用<code>x</code>命令</p>
</li>
<li><p>删除多个字符可以使用<code>d</code>命令，格式为<code>d motion</code>，其中motion表示操作范围的指令，如下</p>
</li>
</ul>
<p><img src="/2019/10/28/blog02/2.png" alt="2"></p>
<p>相应的删除命令如下</p>
<p><img src="/2019/10/28/blog02/3.png" alt="3"></p>
<h2 id="灵活运用数字"><a href="#灵活运用数字" class="headerlink" title="灵活运用数字"></a>灵活运用数字</h2><ul>
<li><p>数字 + motion = 重复多个motion</p>
</li>
<li><p>d + 数字 + motion = 删除多个motion范围</p>
</li>
</ul>
<h2 id="撤销"><a href="#撤销" class="headerlink" title="撤销"></a>撤销</h2><p>普通模式下</p>
<ul>
<li><code>u</code>表示撤销最后一次修改</li>
<li><code>U</code>表示撤销对整行的修改</li>
<li><code>Ctrl+r</code>快捷键可以恢复撤销的内容</li>
</ul>
<blockquote>
<p>备注：上面所有的“删除”操作并不是真的删除，它们事实上是存放在VIM的一个缓冲区中，相当于Windows的剪切功能。（VIM称为寄存器）</p>
</blockquote>
<h1 id="粘贴拷贝替换修改"><a href="#粘贴拷贝替换修改" class="headerlink" title="粘贴拷贝替换修改"></a>粘贴拷贝替换修改</h1><h2 id="粘贴命令"><a href="#粘贴命令" class="headerlink" title="粘贴命令"></a>粘贴命令</h2><p>使用<code>p</code>命令可以将最后一次删除的内容粘贴到光标之后。（大写的<code>P</code>则是粘贴到光标之前）</p>
<blockquote>
<p>注意：如果需要粘贴的是整行为单位，那么<code>p</code>命令将在光标的下一行开始粘贴；如果拷贝的是非整行的局部字符串，那么<code>p</code>命令将在光标后开始粘贴。</p>
</blockquote>
<h2 id="拷贝命令"><a href="#拷贝命令" class="headerlink" title="拷贝命令"></a>拷贝命令</h2><p>vim使用<code>y</code>来实现拷贝，语法如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">y [数字] motion</span><br></pre></td></tr></table></figure>

<h2 id="替换命令"><a href="#替换命令" class="headerlink" title="替换命令"></a>替换命令</h2><ul>
<li><p><code>r</code>命令用于替换光标所在的字符，做法是先将光标移动到需要替换的字符处，按一下<code>r</code>键，然后输入新的字符。</p>
</li>
<li><p>在键入<code>r</code>命令之前输入数字，表示从光标处开始，将多个字符统一替换为新字符。</p>
</li>
<li><p><code>R</code>命令可以进入到替换模式</p>
</li>
</ul>
<h2 id="修改命令"><a href="#修改命令" class="headerlink" title="修改命令"></a>修改命令</h2><p>修改和替换是不一样的，修改会进入插入模式，替换不会进入插入模式。</p>
<p>使用<code>c</code>命令实现修改:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">c [数字] motion</span><br></pre></td></tr></table></figure>

<p><img src="/2019/10/28/blog02/4.png" alt="4"></p>
<h1 id="文件信息"><a href="#文件信息" class="headerlink" title="文件信息"></a>文件信息</h1><p>有时候我们需要当前文件的文件信息，比如文件名、文件总行数等。可以使用<code>Ctrl+g</code>来查看文件信息。</p>
<h2 id="跳转"><a href="#跳转" class="headerlink" title="跳转"></a>跳转</h2><p><code>行号+G</code>可以快速跳转。</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/27/blog01/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/27/blog01/" itemprop="url">Linux Windows双系统安装问题记录</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-27T10:53:48+08:00">
                2019-10-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Linux/" itemprop="url" rel="index">
                    <span itemprop="name">Linux</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>安装了windows和Linux双系统，Linux版本为Ubuntu18.04TLS。</p>
<h1 id="连接有线校园网"><a href="#连接有线校园网" class="headerlink" title="连接有线校园网"></a>连接有线校园网</h1><p>下载锐捷客户端Linux版本，解压。进入到<code>rjsupplicant</code>目录下，在终端运行如下命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo ./rjsupplicant.sh -u username -p password -d 1</span><br></pre></td></tr></table></figure>

<p>将username和password替换为校园网的用户名和密码即可。</p>
<h1 id="安装显卡驱动"><a href="#安装显卡驱动" class="headerlink" title="安装显卡驱动"></a>安装显卡驱动</h1><p>显卡为GeForce GTX 2070，Linux自带的显卡驱动显示不了2K的分辨率。</p>
<ol>
<li><p>首先卸载系统里低版本的英伟达显卡驱动</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-get purge nvidia*</span><br></pre></td></tr></table></figure>
</li>
<li><p>把显卡驱动加入PPA</p>
</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo add-apt-repository ppa:graphics-drivers</span><br><span class="line">$ sudo apt-get update</span><br></pre></td></tr></table></figure>

<ol start="3">
<li>查找英伟达显卡驱动最新版本号</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt-cache search nvidia</span><br></pre></td></tr></table></figure>

<p>使用终端命令查看Ubuntu推荐的驱动版本(后面带有recommended)</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ ubuntu-drivers devices</span><br></pre></td></tr></table></figure>

<ol start="4">
<li><p>然后打开系统里的软件和更新，点击附加驱动，选择上面推荐的驱动版本<br><img src="/2019/10/27/blog01/1.png" alt="1"></p>
</li>
<li><p>安装完成后重启系统即可，会发现多了一个名为NVIDIA X Server Settings的显卡驱动应用。</p>
</li>
</ol>
<h1 id="安装中文输入法"><a href="#安装中文输入法" class="headerlink" title="安装中文输入法"></a>安装中文输入法</h1><ol>
<li><p>首先卸载电脑中存在的ibus输入法</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt remove `ibus*`</span><br></pre></td></tr></table></figure>
</li>
<li><p>安装fcitx输入法配置框架</p>
</li>
</ol>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install fcitx-bin fcitx-table</span><br></pre></td></tr></table></figure>

<p>然后打开设置中心，选择<strong>Region &amp; Language &gt; Manage Installed Languages</strong>(会提示The language support is not installed completely,选择Remind me Later)。在<strong>Keyboard input method system:</strong>中选择<strong>fcitx</strong>。</p>
<p><img src="/2019/10/27/blog01/2.png" alt="2"></p>
<p>这时候重启电脑可以看到右上角的fcitx的设置图标。然后开始安装搜狗输入法，进入官网下载安装包，双击安装即可。</p>
<ol start="3">
<li>选用搜狗输入法</li>
</ol>
<p>在终端运行命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ fcitx-configtool</span><br></pre></td></tr></table></figure>

<p>如果未安装图形配置界面，则需执行命令：</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install <span class="string">'fcitx-config-gtk'</span></span><br></pre></td></tr></table></figure>

<p>出现如下界面，点击减号按钮将自带的拼音输入法清除，然后点击加号按钮，搜索我们自己安装的输入法，选择即可。<br><img src="/2019/10/27/blog01/3.png" alt="3"></p>
<p>可以按<strong>Ctrl+Space</strong>来快速切换不同的输入法</p>
<h1 id="声音"><a href="#声音" class="headerlink" title="声音"></a>声音</h1><p>插入耳机没有声音，发现是耳机插在了mic接口，改查spk接口后问题解决。</p>
<h1 id="截屏"><a href="#截屏" class="headerlink" title="截屏"></a>截屏</h1><p>Ubuntu18.04中有自带的截图工具Screenshot，为了方便使用，将截图快捷键设置成熟悉的<strong>ctrl+alt+a</strong></p>
<p>在右上角选择系统设置，<strong>Ｄevices-&gt;Keyboard</strong>，将<strong>Save a screenshot of an area to Pictures</strong>改为Ｃtrl+alt+a即可。<br><img src="/2019/10/27/blog01/4.png" alt="4"></p>
<h1 id="安装vs-code"><a href="#安装vs-code" class="headerlink" title="安装vs code"></a>安装vs code</h1><p>从vs官网下载最新版本，运行下面命令安装即可</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ sudo dpkg -i code_1.39.2-1571154070_amd64.deb</span><br></pre></td></tr></table></figure>

<p>如果安装过程中有如下错误<br><img src="/2019/10/27/blog01/5.png" alt="5"></p>
<p>执行以下命令即可</p>
<figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt --fix-broken install</span><br><span class="line">$ sudo dpkg -i code_1.39.2-1571154070_amd64.deb</span><br></pre></td></tr></table></figure>

<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><a href="https://blog.csdn.net/m0_37343696/article/details/79268886" target="_blank" rel="noopener">Linux系统下锐捷客户端连接方法</a></li>
<li><a href="安装英伟达显卡驱动">Ubuntu 18.04</a></li>
<li><a href="https://www.cnblogs.com/zhuangmingnan/p/9496499.html" target="_blank" rel="noopener">Ubuntu 18.04LTS安装搜狗输入法</a></li>
<li><a href="https://www.jianshu.com/p/502b267ee658" target="_blank" rel="noopener">Ubuntu 18.04安装vscode</a></li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/10/27/Unsupervised Learning Linear Methods/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Liang Qi">
      <meta itemprop="description" content>
      <meta itemprop="image" content="/images/avatar.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Qi-Liang'blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/10/27/Unsupervised Learning Linear Methods/" itemprop="url">Unsupervised Learning —— Linear Methods</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2019-10-27T10:06:33+08:00">
                2019-10-27
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/Machine-Learning/" itemprop="url" rel="index">
                    <span itemprop="name">Machine Learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>Dimension Reduction可分成两种，<strong>Generation</strong>(无中生有)和<strong>Reduction</strong>(化繁为简)。Unsupervised Learning可以分为两大类，一种是Clustering，一种是<strong>Dimension</strong> <strong>Reduction</strong>。</p>
<p>化繁为简的意思是，现在有很多种不同的input，比如一个function，它可以input看起来像树的东西，output都是抽象的树。也就是把本来比较复杂的input,变成比较简单的output。在做unsupervised learning的时候，通常只会有function的其中一边。比如我们要找一个function，它可以把所有的树都变成抽象的树，但是我们所拥有的training data，就只有一大堆的各种不同的image，我们不知道它的output应该要长什么样。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/1.png" alt="1"></p>
<p>另外一个Unsupervised Learning会做的事情是Generation。它做的事情是，找一个function,随机给它一个input，比如输入不同的数字，它就会output不同的树。在这个task里，我们要找的这个可以画图的function，只有这个function的output,但是没有这个function的input。（只有一大堆的image,但是不知道输入什么样的code才可以得到这些image）</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/2.png" alt="2"></p>
<h1 id="Clustering"><a href="#Clustering" class="headerlink" title="Clustering"></a>Clustering</h1><p>假设我们要做image的clustering,就是有一大堆image，我们要把它们几类，每一个cluster就是一个标签，这样就把本来有些不同的image，都用同一个class来表示。、</p>
<p>这里最重要的一个问题是，到底应该要有几个cluster。这个问题没有什么好的方法，就跟neural network要几层一样。</p>
<h2 id="K-means"><a href="#K-means" class="headerlink" title="K-means"></a>K-means</h2><p>在Clustering方法里面，最常用的就是<strong>k-means</strong>。假设我们有一大堆的data，它们都是unlabeled的，$X = \{x^1,\cdots,x^n,\cdots,x^N\}$,其中每一个$x$可能代表一张image，我们要把它做成K个cluster。先找这些cluster的center，假如每一个object都是用vector来表示的话，那么center也是一样长度的vector。每一个cluster要找一个center,所以需要$c^1$到$c^K$个center。这些初始的center怎么来呢？可以从training data里面随机地找K个object出来，作为K个center。接下来，要对所有在training data里面的x，都要决定它属于1到K的哪一个cluster（看它与哪一个cluster center最接近）。之后再做update</p>
<p>K-means步骤总结如下:</p>
<ul>
<li><p>Clustering $X=\{x^1,\cdots,x^2,\cdots,x^N\}$ into K clusters</p>
</li>
<li><p>Initialize cluster center $c^i,i=1,2,\cdots,K$(K random $x^n$ from X)</p>
</li>
<li><p>Repeat</p>
</li>
<li><ul>
<li>For all $x^n$ in $X$:</li>
</ul>
</li>
</ul>
<p>$$b_i^n=<br>\begin{cases}<br>1&amp; x^n\text{ is most “close” to } c^i\\<br>0&amp; \text{Otherwise}<br>\end{cases}$$</p>
<ul>
<li><ul>
<li>Updating all $c^i$:</li>
</ul>
</li>
</ul>
<p>$$c^i = \sum_{x^n}b^n_ix^n/\sum_{x^n}b_i^n$$</p>
<p>之所以在做initialization的时候会直接从database里面去挑K个object出来做center，一个很重要的原因是，假设我们纯粹随机的，而不是从data point里面挑的，很有很能在第一次assign这个object的时候，就没有任何一个example跟某一个cluster很像，那么update的时候，程序会segmentation fault。</p>
<h2 id="HAC"><a href="#HAC" class="headerlink" title="HAC"></a>HAC</h2><p>clustering有另外一个方法叫做<strong>Hierarchical Agglomerative Clustering(HAC)</strong>,这个方法是先建一个tree，假设现在有5个example，要把他做cluster，先做一个tree structure。即把这5个example两两去算它们的相似度，然后挑最相似的pair出来，将它们平均起来得到一个新的vector，现在就变成有4个example了。然后再把这4笔data两两去算他们的相似度，依次类推，这样就建立出一个tree structure。在这个tree里面，比较早的分支代表比较不像。接下来就是做clustering，选择一个threshold对tree structure进行切分，得到几个cluster，如下图。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/3.png" alt="3"></p>
<p>HAC和K-means最大的差别就是如何决定cluster的数目，在K-means里面我们要决定K的值是多少，而HAC不直接决定几个cluster，而是要决定切在树的structure的哪里。</p>
<h1 id="Distributed-Representation"><a href="#Distributed-Representation" class="headerlink" title="Distributed Representation"></a>Distributed Representation</h1><h2 id="Dimension-Reduction"><a href="#Dimension-Reduction" class="headerlink" title="Dimension Reduction"></a>Dimension Reduction</h2><p>但是，光只做cluster是非常卡的。在做cluster的时候，我们就是以偏概全，因为每一个object都必须要属于某一个cluster，但这样其实是比较粗糙的，应该要用一个vector来表示Object，这个vector里面的每一个dimension就代表了某一种特质，一种attribute。这件事情就叫做distributed representation。如果原来的object是一个非常high dimension的东西，比如image。那现在用它的attribute来描述，它就会从比较高维的空间变成比较低维的空间。这件事情就是Dimension Reduction。</p>
<p>为什么Dimension Reduction可能是有用的？举例来说，假设data的分布如下图，用3D的空间来描述这些data其实是很浪费的，从直观上就能知道，其实可以把左边的data“摊开”，变成右边的样子，所以其实只需要在2D的空间，就可以描述3D的information。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/4.png" alt="4"></p>
<p>再举一个比较具体的例子，我们考虑MNIST，在MNIST里面，每一个input的digit是一个image,它都用$28\times 28$的dimension来描述它。但实际上多数$28\times 28$的dimension的vector,把它转成一个image，看起来都不像一个数字。所以在这个$28\times 28$的空间里面，是digit的vector，其实是很少的。要描述一个digit，或许根本不需要$28\times 28$维。</p>
<p>比如下面有一堆3，这堆3如果是从Pixel来看待它的话，要用$28\times 28$来描述每一个image。而实际上这些3只需要用一个维度就可以来表示，它们都可以用中间的3选择某一个角度得到。所以只需要一维就可以描述这些image。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/5.png" alt="5"></p>
<p>要怎么做Dimension Reduction呢？我们要找一个function，这个function的input是一个vector $\bf{x}$，它的output是另外一个vector $\bf{z}$。z的维度要比x小。在Dimension Reduction里面，最简单的方法是<strong>Feature Selection</strong>。这个方法比较简单，我们将data的分布拿出来看一下，本来在二维的平面上，但我们发现其实都集中在$x_2$的dimension而已，$x_1$这个dimension没什么用，把它拿掉，这样就做到了Dimension Reduction这件事情。这个方式不是总是有用，因为有时候任何一个dimension都不能拿掉。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/6.png" alt="6"></p>
<h2 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h2><p>另外一个方法是<strong>Principle Component Analysis(PCA)</strong>,它做的事情是，假如function是一个很简单的linear function，input $\bf{x}$与output $\bf{z}$之间的关系就是一个linear的transform:</p>
<p>$$\bf{z} = W\bf{x}$$</p>
<p>现在要做的，就是根据一大堆的\bf{x},把W找出来（我们现在不知道\bf{z}长什么样）。</p>
<p>为了找出W，我们现在考虑一个比较简单的one dimensional的case，即\bf{z}是一维的。z是一个scalar，那么W其实就是一个row vector,用$w^1$表示。于是就有：</p>
<p>$$z_1 = w^1\cdot x$$</p>
<p>另外还有如下很必要的假设：</p>
<p>$$||w^1||_2 = 1$$</p>
<p>有了上面假设，那么$z_1$就意味着$x$在$w^1$上面的投影值。所以我们现在做的事情就是把一堆$x$透过$w^1$把它投影变成$z_1$，这样就得到一堆$z^1$（project all the data points $x$ onto $w^1$,and obtain a set of $z_1$）。现在的问题是，这个$w_1$应该长什么样子？我们要选哪一个$w^1$呢？</p>
<p>假设下面是$x$的分布，每一个点代表一只宝可梦，横坐标为攻击力，纵坐标为防御力。如果我们要把二维投影到一维，应该要选什么样的$w^1$？选择不同的$w^1$方向，最后得到的结果会是不一样的。我们的目标是：希望选一个$w^1$，它经过projection后得到的$z_1$的分布是越大越好的。下图中选择红色箭头方向会有比较大的variance，所以$w^1$的方向应该指向该方向。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/7.png" alt="7"></p>
<p>如果我们用equation来表示的话，我们要去maximize的对象是$z_1$的variance：</p>
<p>$$Var(z_1) = \sum_{z_1}(z_1 - \bar{z_1})^2\ \ \ \ \ \  ||w^1||_2 = 1$$</p>
<p>但是我们可能不是只要投影到1维，比如想要投影到一个二维的平面。</p>
<p>$$z_1 = w^1\cdot x$$  $$z_2 = w^2\cdot x$$</p>
<p>其中$z_1$和$z_2$串起来就是$\bf{z}$。找$z_2$与找$z_1$一样，首先我们希望$w^2$的2-norm是1，并且$z_2$的分布越大越好。但如果只是让$Var(z_2)$越大越好，那找出来的不就是$w^1$吗，所以还需要再加一个constraint，这个constraint是：$w^2$要与$w^1$垂直（orthogonal）,即$w^1\cdot w^2=0$。</p>
<p>要project到几维是需要我们自己决定的（和cluster、hidden layer的决定一样）。如果要project到$K$维，就需要找$w^1$到$w^K$,最后的$\bf{W}$如下</p>
<p>$$\bf{W} =\begin{bmatrix}<br>{(w^1)^T}\\<br>{(w^2)^T}\\<br>{\vdots}\\<br>{(w^K)^T}\\<br>\end{bmatrix}$$</p>
<blockquote>
<p>找出来的$\bf{W}$是一个orthogonal matrix。因为的行向量长度为1并且两两正交。</p>
</blockquote>
<p>接下来的问题是怎么解出$w^1$到$w^K$，这里要用到<strong>Lagrange multiplier</strong>，（其实也可以将PCA描述成一个neural network，然后用Gradient Descent的方法来解），方法如下图：</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/8.png" alt="8"></p>
<p>$w^1$的解法如下：</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/9.png" alt="9"></p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/10.png" alt="10"></p>
<p>上图中第二个微分式子为：$(w^1)^TSw^2 - \alpha (w^1)^Tw^2 -\beta (w^1)^Tw^1 = 0$</p>
<h3 id="PCA-decorrelation"><a href="#PCA-decorrelation" class="headerlink" title="PCA - decorrelation"></a>PCA - decorrelation</h3><p>$\bf{z} = Wx$</p>
<p>上式有一个神奇的地方，就是$z$的covariance会是一个diagonal matrix（$Cov(z) = D$）。也就是说，如果我们今天做PCA，原来的data distribution可能是下图左边的样子，做完PAC以后，会做decorrelation，会让不同的dimension间的convariance是0。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/11.png" alt="11"></p>
<p>这样做有时候会有帮助，假设现在的PCA所得到的新的feature，即$\bf{z}$是一种新的feature，这个新的feature是要给其他Model用的，而这个model假设是一个generative model，用Gaussian来描述某一个class的distribution。而在做这个Gaussian假设的时候，假设input data，它的covariance是diagnoal（不同的dimension之间没有correlation），这样可以减少参数量。把原来的data做PCA之后，在丢给其他的model，其他的model就可以假设现在的input data的dimension间没有corelation，所以它就可以用比较简单的Model来处理input data，这样就可以避免overfitting的情形。</p>
<p>这件事情的证明也是非常trivial的。</p>
<p>$$Con(z) = \sum(z - \bar{z})(z - \bar{z})^T = WSW^T$$ $$S = Cov(x)$$</p>
<p>所以有：</p>
<p>$$Cov(z) = WS[w^1\ \cdots \ w^K] = W[Sw^1\ \cdots \ Sw^K] = W[\lambda_1w^1\ \cdots \ \lambda_Kw^K]$$ $$ = [\lambda_1Ww^1\ \cdots \ \lambda_KWw^K] = [\lambda_1e_1\ \cdots \ \lambda_Kw_K]$$</p>
<p>以上部分或许不是太容易理解，我们从另外一个角度来看PCA。另一个比较直观的PCA如下，假设我们考虑的是手写数字，这些数字其实是由一些basic component所组成，这些component就可能代表笔画。举例来说，人手写的数字可能由这些basic component所组成，把这些component加起来以后，就可以得到一个数字。这些basic component其实就是一个个的vector，假设我们现在考虑的是MNIST的话，MNIST的一张image是$28\times 28$pixel，也就是$28\times 28$维的一个vector，这些component其实也就是$28\times 28$维的vector，把这些vector加起来以后，所得到的vector就代表了一个digit，</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/12.png" alt="12"></p>
<p>整理一下有下式：</p>
<p>$$x - \bar{x} \approx c_1u^1 + c_2u^2 + \cdots + c_Ku^K = \hat{x}$$</p>
<p>现在假设我们不知道这些$u^1$到$u^K$这$K$个vector长什么样子，要怎么找这K个vector出来呢？我们要做的事情就是找出$u^1$到$u^K$，使得$x - \bar{x}$与$\hat{x}$越接近越好。它们中间的差，没有办法用component来描述的部分，叫做<strong>reconstruction error</strong>。我们要找K个vector，来minimize这个reconstruction error。reconstruction error写成$L$，它的公式如下：</p>
<p>$$L = \min_{\{u^1,\cdots,u^K\}} \sum \left|\left|((x - \bar{x}) - (\sum^K_{k=1}c_ku^k))\right|\right|_2 \tag{1}$$</p>
<p>先来回顾一下PCA，在PCA里，我们要找一个matrix $W$,原来的vector $\bf{x}$乘上$W$以后，就得到Dimension Reduction以后的结果$\bf{z}$，下式中的$w_1$到$w_K$都是covariance matrix的eigenvector。事实上，如果要解式子(1)，找出$u^1$到$u^K$，$w^1$到$w^K$，就是由PCA找出来的这个解，其实就是可以让式子(1)最小化。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/13.png" alt="13"></p>
<p>用一个比较简单的方式来证明。我们现在在database里面有一大堆的$x$，现在假设有一个$x^1$，有：</p>
<p>$$x^1 - \bar{x} \approx c_1^1u^1 + c_2^1u^2 + \cdots$$</p>
<p>database里面不只有$x^1$，所以可以表示如下：</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/14.png" alt="14"></p>
<p>上图中Matrix X的column的数目就是data的数目，我们希望左右两边的matrix越接近越好。如何解这个问题呢？在线代里面，每一个matrix X,都可以用SVD，把它拆成一个3个Matrix的乘积。如下，其中$k$是component的数目。矩阵$U$对应上面左边的矩阵($u^1$到$u^K$组成)，矩阵$\Sigma$和$V$的乘积对应上面右边的矩阵($c_n^m$组成)。如果我们用SVD的方法将$X$拆成这三个matrix相乘的结果，那么右边这三个Matrix相乘的结果跟左边这个matrix它们之间的Frobenius的norm是会被minimize的。也就是说，用SVD提供给我们的一个matrix拆解方法，<br>它跟左边的matrix是最接近的。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/15.png" alt="15"></p>
<p>解出来的结果是，U的k个column其实就是一组orthonormal的vector，这组orthonormal的vector，它们是$XX^T$的eigenvector。而这里总共有K个orthonormal的vector，这K个vector就对应到$XX^T$最大的k个eignenvalue的eigenvector。$XX^T$就是covariance matrix，我们之前PCA找出来的那一些$w$就是covariance matrix的eigenvector，而我们做SVD，解出来的U的每一个column，就是covariance matrix的eigenvector。所以U这个解，其实就是PCA的出来的解。即PCA得到的w其实就是component。</p>
<h3 id="Autoencoder"><a href="#Autoencoder" class="headerlink" title="Autoencoder"></a>Autoencoder</h3><p>我们现在已经知道，从PCA找出来的$w^1$到$w^K$就是K个component($u^1$到$u^K$),根据component linear combination的结果$\hat{x}$：</p>
<p>$$\hat{x} = \sum^K_{k=1}c_kw^k$$</p>
<p>我们希望$\hat{x}$与$x - \bar{x}$越接近越好。我们现在已经根据SVD，找出来W，那么$c_k$的值到底应该是多少？这个问题其实是在说，现在有$K$维的vector，它们做span以后，得到一个space，现在用$c_1$到$c_K$对他做linear combination，怎样才能最接近$x-\bar{x}$。因为$w^1$到$w^K$是orthonormal的，所以要得到$c_k$其实很简单，只要把$x - \bar{x}$与$w^k$做inner product，得到的就是$c_k$：</p>
<p>$$c^k = (x-\bar{x})\cdot w^k$$</p>
<p>上面做linear combination的事情，其实可以想成用neural network来表示。假设$x - \bar{x}$就是一个vector，这边写成一个3维的vector,假设K=2,我们先算出$c_1$和$c_2$（innear product）,也就是把$x - \bar{x}$的每一个component乘上w^1的每一个component，就得到$c_1$，这就好像是说，$x - \bar{x}$是neuron network的input，$c_1$是一个neuron，$w_1^1$、$w_2^2$是neuron的weight，这个neuron它是一个linear的neuron，它没有activation function。我们希望这个neural network的output跟$x - \bar{x}$越接近越好。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/16.png" alt="16"></p>
<p>我们会发现，其实PCA可以表示成一个neural network，这个neural network只有一个hidden layer，这个hidden layer是linear的activation function。我们train这个neural network的criterion是要让output与input越接近越好。这个东西就叫做<strong>Autoencoder</strong>。</p>
<blockquote>
<p>假设现在的weight不是用PCA找eigenvector的方法，而是直接用neural network通过Gradient Descent训练得到$w^1$到$w^K$,那么这个结果会和用PCA得到的结果一样吗？</p>
</blockquote>
<p>其实是会不一样的，PCA解出来的W，它们是orthonormal的。如果用neural network训练得到的结果，没有办法保证会是垂直的。我们在前面的SVD证明里面已经说PCA导出来的这组解$w^1$到$w^K$，它可以让我们的reconstruction error被minimize。如果用Gradient descent的方法去硬解一发，其实也不可能比PCA找出来的reconstruction error还要小。</p>
<p>所以，如果是在linear的情况下，或许就会直接用PCA来找W，是比较快的。用neural network或许是比较麻烦的。但是用neural network的好处是它可以是deep的，这就是之后会讲的<strong>deep autoencoder</strong>。</p>
<h3 id="Weakness-of-PCA"><a href="#Weakness-of-PCA" class="headerlink" title="Weakness of PCA"></a>Weakness of PCA</h3><p>PCA其实有一些很明显的弱点。一个就是，因为它是unsupervised，所以今天假如给它一大堆点，没有label，那对PCA来说，假设把它project到一维上，PCA会找一个可以让data variance最大的那一个dimension，如下图。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/17.png" alt="17"></p>
<p>但是有一个可能是，或许这两组data point，它们分别代表了两个class，如果用PCA这个方法来做Dimension Reduction的话,就会使得这两个蓝色和橙色的class被merge在一起。它们在PCA上找出来的single dimension上，完全被混在一起，无法分别。这个时候可能就需要引入label data。<strong>LDA(linear discriminant analysis)</strong>是考虑这个labeled data的一个降维方法，但它是supervised的。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/18.png" alt="18"></p>
<p>另外一个PCA的弱点是它是linear的，如下图点的分布像是S形的，我们期待做dimension reduction以后，可以把S形的曲面，把它拉直，但这件事情对PCA来说是做不到的。因为将S形的曲面拉直是一个non-linear的transformation。把S行的曲面做PCA，得到的结果如下：</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/19.png" alt="19"></p>
<hr>
<p>一个实际的例子，假设每只宝可梦可以用一个6维的vector来表示，我们现在来用PCA来分析它。在用PCA的时候常常会问的一个问题是，需要有多少个component。到底要把它project到几维，资讯量才足够呢？这个取决于你想要做什么。假设要做visualization，因为现在每一个宝可梦都是6维，没有办法了解这些宝可梦之间的特性有什么样的关系，所以可能就会想把它project到二维，就比较容易分析。要用多少principle component，就好像是neural network要有几层layer，每层layer要有多个neuron一样，这个是要我们自己决定的。一个常见的方法是，计算每一个principle component的$\lambda$，我们知道每一个principle component就是一个eigenvector，这个eigenvector又对应一个eigenvalue，也就是$\lambda$。这个eigenvalue代表我们用这个principle component去做dimension reduction的时候，在principle component的dimension上，它的variance有多大，那个variance就是$\lambda$。今天这个宝可梦的data总共有6维，所以它的covariance matrix是6维，所以可以找出6个eigenvector和6个eigenvalue。我们现在来计算一下每个eigenvalue的ratio（把每个eigenvalue除以6个eigenvalue的总和），得到的结果如下，从中可以看出第五个和第六个principle component它们的作用其实是比较小的。用这两个dimension来做projection的时候，project出来的variance其实是很小的。这表示，现在宝可梦的这些特性在第五个和第六个principle component上是没有太多information。所以，如果我们今天要分析宝可梦的data的话，感觉只需要前面4个principle component就好了。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/20.png" alt="20"></p>
<p>做了PCA以后，得到的4个principle component如下，每一个principle component是一个六维的vector。那么每一个principle component它做的事情是什么呢？可以看到第一个principle component每一个dimension都是正的，所以它代表这只宝可梦的强度。第2个principle component它在Def是正值，在Speed处是负值，也就是宝可梦防御力提升的时候，它的速度会下降。其他的principle component也有各自的功能。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/21.png" alt="21"></p>
<p>用PCA做手写数字辨识的话，每一个component都是一个image。用PCA得到前30个component如下，用这些component做linear combination，就可以得到所有的数字。所以这些component就叫做Eigen-digit。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/22.png" alt="22"></p>
<p>同理，如果做人脸辨识的话，找出来的principle component就叫做Eigen-face。</p>
<h3 id="NMF"><a href="#NMF" class="headerlink" title="NMF"></a>NMF</h3><p>注意principle component不一定是要加起来，也可以减掉它们，所以component不一定都是类似笔画的东西，如Eigen-face每一个就是一张完整的脸。如果要得到类似笔画的东西，要用到另外一个技术<strong>NMF(Non-negative matrix factorization)</strong></p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/23.png" alt="23"></p>
<p>之前说过，PCA可以看作是对matrix X做SVD，SVD就是一种矩阵分解的技术。它分解出来的两个两个matrix的值，可以是正的，也可以是负的。如果用NMF的话，我们会强迫所有的component的weight都是正的，这样的好处就是，现在一张iamge必须由component叠加得到，而不能是由复杂的东西减去一部分得到。另外，所有的component的每一个dimension，也都必须是正的。</p>
<ul>
<li><p>Non-negative matrix factorization(NMF)</p>
<ul>
<li><p>Forcing $a_1,a_2,\cdots$ be non-negative</p>
<ul>
<li>additive combination</li>
</ul>
</li>
<li><p>Forcing $w^1,w^2,\cdots$ be non-negative</p>
<ul>
<li>More like “parts of digits”</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>NMF在手写数字辨识上得到的的principal component如下，现在的component就可以看作是笔画了。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/24.png" alt="24"></p>
<h1 id="Matrix-Factorization"><a href="#Matrix-Factorization" class="headerlink" title="Matrix Factorization"></a>Matrix Factorization</h1><p>有时候会有两种object，它们之间是受到某种共通的latent factor去操控的。假设我们现在调查每个人手上公仔的数目，下面的A到E代表5个人，</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/25.png" alt="25"></p>
<p>我们会发现，在上面的matrix中，每个table里的block并不是随机出现的。例如，买凉宫春日公仔的人，会比较有可能有御坂美琴的公仔。这是因为，每一个人跟每一个角色背后是有一些共同的特性，一些共同的factor来操控(There are some common factors behind otakus and characters)。</p>
<p>动漫宅或许可以分为两种，萌傲娇和萌天然呆，每一个人，其实就是在这两种属性的组合。每一个角色，也有这两种属性，所以也可以用一个二维的vector来描述它。如果某一个人萌的属性跟某一个角色他本身所具有的属性是match的话（即它们背后的vector很像，比如inner product的值很大），那么这个人就会买很多对应角色的公仔。所以它们匹配的程度取决于他们背后这个latent factor是不是匹配的。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/26.png" alt="26"></p>
<p>问题在于一个人的属性分配是没有办法直接被观察的（没有人在意阿宅心里在想什么(<em>^_^</em>)），另外也没有办法知道每个动漫人物背后的属性是什么。我们有的只是动漫人物跟阿宅中间的关系，我们需要凭借这个关系，去推论出每一个人跟每一个动漫人物他们背后的latent factor。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/27.png" alt="27"></p>
<p>我们现在做一个假设：Matrix X里面的每一个element都来自于两个vector的inner product</p>
<p>$$r^A\cdot r^1 \approx 5$$  $$r^B\cdot r^1 \approx 4$$  $$r^C\cdot r^1 \approx 1$$</p>
<p>用数学式表示的话如下图，$K$是latent factor的数目，它的值我们是每办法知道的，上面我们将人分成萌傲娇和萌天然呆其实是不精确的分析方式，如果我们有更多的data的话，应该可以更精准知道要有多少factor。但是实际上要有多少factor这件事必须要试出来，就像是principal component的数目或neural network的层数一样。如下图，我们要做的事情就是找一组$r^A$到$r^E$和一组$r^1$到$r^4$，将右边两个matrix相乘后，结果和Matrix X越接近越好。我们可以用SVD来解，$\Sigma$并到左边或右边都可以。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/28.png" alt="28"></p>
<p>有时候可能会遇到一个问题，就是有一些information是missing的。比如我们并不知道ABC手上有没有小野寺的公仔，有可能只是在他所在的地区没有发行这个公仔而已。所以不知道如果发行的话，他到底会不会买。所以下表中有些数据是问号，这样再做SVD就会有点卡。如果在matrix X上有一些missing value的话，我们还是可以做的。我们就用Gradient Descent的方法来做它。我们写一个loss function，如下图，其重点在于，在summation over这些element的时候，可以避开这些missing data，我们只算值有定义的部分。剩下的部分用Gradient descent就可以了。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/29.png" alt="29"></p>
<p>算出了$r^1$到$r^4$和$r^A$到$r^E$,即每个人和每个角色对应的vector，有了这些data后，就可以预测missing value（将相应的vector做inner product），即每个人会买相应公仔的数目。所以这种方法，常用在推荐系统里面。（例如预测某个人会不会喜欢某部电影）</p>
<p>其实，上面的model可以做更精致一点。A背后的latent factor乘上1背后的latent factor，得到的结果就是table上面的数值。但事实上，可能还会有别的因素会操纵他的数值。更精确的写法如下：</p>
<p>$$r^A \cdot r^1 \approx 5  \rightarrow r^A \cdot r^1 + b_A + b_1 \approx 5 $$</p>
<p>$b_A$是与A有关的scalar，它代表A有多喜欢买公仔。$b_1$是与1有关的scalar，它代表该角色的公仔有多想让别人购买。这件事情是和属性无关的。改一下要minimize的式子：</p>
<p>$$L = \sum_{(i,j)}(r^i\cdot r^j + b_i + b_j - n_{ij})^2$$</p>
<p>用Gradient descent找出$r^i$、$r^j$、$b_i$、$b_j$的值。如果想要知道更多，可以参考链接2，它是Matrix Factorization在Netflix上面的应用。</p>
<h2 id="Matrix-Factorization-for-Topic-analysis"><a href="#Matrix-Factorization-for-Topic-analysis" class="headerlink" title="Matrix Factorization for Topic analysis"></a>Matrix Factorization for Topic analysis</h2><p>Matrix Factorization的另一个应用是<strong>Topic analysis</strong>。将Matrix Factorization用在Topic analysis上面的话就叫做<strong>Latent semantic analysis(LSA)</strong>。它的技术和上面所讲是一模一样的，只不过是换了名词而已。charater换成了document,otakus换成了word，table里面的值就是Term frequency，即每个word在document里面出现的次数。有时候，我们不知会用Term frequency,而是会把Term frequency再乘上一个weight，代表这个term本身有多重要。通常怎么evaluate一个term重不重要呢？有很多方法，一个常用的就是<strong>inverse document frequency</strong>。</p>
<p><img src="/2019/10/27/Unsupervised Learning Linear Methods/30.png" alt="30"></p>
<p>在这个task里面，如果今天把这个matrix做分解的话，就会找到每一个documnet背后的latent factor，和每一个词汇背后的latent factor。这里的latent factor可能指的是topic，即某一个document（或word），它背后要谈的主题有多少部分与财经有关，有多少部分与政治有关等等。</p>
<p>Topic analysis的方法多如牛毛，他们基本的精神是差不多的，但是有很多各种各样的变化，常见的是<strong>Probability latent semantic analysis(PLSA)</strong>和<strong>latent Dirichlet allocation(LDA)</strong></p>
<h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ol>
<li><p><a href="https://www.researchgate.net/publication/2538030_Algorithms_for_Non-negative_Matrix_Factorization" target="_blank" rel="noopener">Algorithm for Non-negative Matrix Factorization</a></p>
</li>
<li><p><a href="https://datajobs.com/data-science-repo/Recommender-Systems-[Netflix].pdf" target="_blank" rel="noopener">MATRIX FACTORIZATION TECHNIQUES FOR RECOMMENDER SYSTEMS</a></p>
</li>
</ol>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><span class="space">&hellip;</span><a class="page-number" href="/page/5/">5</a><a class="extend next" rel="next" href="/page/2/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image" src="/images/avatar.jpg" alt="Liang Qi">
            
              <p class="site-author-name" itemprop="name">Liang Qi</p>
              <p class="site-description motion-element" itemprop="description"></p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">50</span>
                  <span class="site-state-item-name">日志</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">分类</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">标签</span>
                </a>
              </div>
            

          </nav>

          

          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Liang Qi</span>

  
</div>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Pisces</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  


  











  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  

  
  
    <script type="text/javascript" src="/lib/canvas-nest/canvas-nest.min.js"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>

<!-- 页面点击小红心 -->
<script type="text/javascript" src="/js/src/clicklove.js"></script>